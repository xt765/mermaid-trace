# User Guide

## Table of Contents

- [Introduction](#introduction)
- [How It Works](#how-it-works)
- [Concurrency & Trace IDs](#concurrency--trace-ids)
- [Auto-Instrumentation & Patching](#auto-instrumentation--patching)
- [Context Inference](#context-inference)
- [Diagram Management](#diagram-management)
  - [Intelligent Collapsing](#intelligent-collapsing)
  - [Exception Stack Traces](#exception-stack-traces)
  - [Simplified Object Representation](#simplified-object-representation)
- [Advanced Configuration](#advanced-configuration)
  - [Async Mode (Performance)](#async-mode-performance)
  - [Data Capture Control](#data-capture-control)
  - [Explicit Naming](#explicit-naming)
  - [Flexible Handler Configuration](#flexible-handler-configuration)
- [Production Best Practices](#production-best-practices)
  - [Handling Long-Running Systems](#handling-long-running-systems)
  - [Request-Level Tracing (Recommended)](#request-level-tracing-recommended)
  - [Sampling Tracing](#sampling-tracing)
- [CLI Viewer](#cli-viewer)

## Introduction

MermaidTrace bridges the gap between code execution and architectural visualization. Unlike static analysis tools, it traces *actual* runtime calls, giving you a true picture of your system's behavior.

## How It Works

1.  **Decorate**: You place `@trace` on functions you want to appear in the diagram.
2.  **Intercept**: When the function runs, MermaidTrace logs a "Request" event (`->>`).
3.  **Execute**: The function body executes.
4.  **Return**: MermaidTrace logs a "Return" event (`-->>`) with the return value.
5.  **Visualize**: The events are written to a `.mmd` file, which renders as a sequence diagram.

## Concurrency & Trace IDs

MermaidTrace is built for modern async applications and distributed systems. It automatically handles concurrent requests by assigning a unique **Trace ID** to each flow.

- **Automatic Generation**: A new Trace ID is generated when a flow starts (if one doesn't exist).
- **Propagation**: The ID is stored in `contextvars`, ensuring it follows `await` calls and background tasks automatically.
- **Distributed Tracing**:
    - **FastAPI Middleware**: Automatically extracts `X-Trace-ID` and `X-Source` from incoming request headers.
    - **Header Injection**: When using `patch_object` on libraries like `requests`, the Trace ID is automatically injected into outgoing request headers, allowing for cross-service visualization.

*Note: Currently, all traces are written to the same file. Use the Trace ID in the logs to filter specific sessions if needed.*

## Auto-Instrumentation & Patching

Manually adding `@trace` to every function can be tedious for large classes or external libraries.

### Class Tracing (`trace_class`)

Use `@trace_class` to trace all public methods in a class at once.

```python
from mermaid_trace import trace_class

@trace_class
class MyService:
    def method_a(self): pass
    def method_b(self): pass
```

### Patching Third-Party Libraries (`patch_object`)

If you want to trace calls inside an external library (like `requests`), use `patch_object`.

```python
import requests
from mermaid_trace import patch_object

# Now all calls to requests.get will appear in your diagram
patch_object(requests, "get", name="Requests")
```

## Context Inference

One of the most powerful features is **Context Inference**.

In a sequence diagram, every arrow has a `Source` and a `Target`.
- `Target` is easy: it's the function/class being called.
- `Source` is hard: it's *who called* the function.

MermaidTrace uses Python's `contextvars` to track the "Current Participant".

**Example:**
1.  `A` calls `B`.
2.  Inside `A`, the context is set to "A".
3.  When `B` is decorated with `@trace`, it sees the context is "A", so it draws `A ->> B`.
4.  Inside `B`, the context is updated to "B".
5.  If `B` calls `C`, `C` sees the context is "B", so it draws `B ->> C`.

This means you usually only need to set the `source` on the *entry point* (the first function).

## Diagram Management

### Diagram Storage Convention

To keep your project root clean, it is recommended to store generated `.mmd` files in a `mermaid_diagrams/` directory. A common structure for this directory is:

- `mermaid_diagrams/examples/`: Diagrams generated by example code.
- `mermaid_diagrams/tests/`: Diagrams generated by test cases.
- `mermaid_diagrams/flows/`: Diagrams generated by actual business logic flows.

When configuring, simply specify the relative path:
```python
configure_flow("mermaid_diagrams/flows/user_login.mmd")
```

### Intelligent Collapsing

When a function is called many times in a loop, or when repetitive call sequences occur, the sequence diagram can become extremely cluttered and difficult to read. MermaidTrace features advanced **Stateful Pattern Detection**:

1.  **Single Repeat Collapsing**:
    When the exact same function is called multiple times consecutively (e.g., in a `for` loop), it is collapsed into a single arrow with a counter (e.g., `process_item (x10)`).
2.  **Pattern Sequence Collapsing (Loop Detection)**:
    MermaidTrace can identify complex repeating patterns, such as `A -> B -> C -> A -> B -> C`. This entire sequence is recognized as a recurring loop and merged while preserving the pattern's structure.
3.  **Automatic Flush**:
    When a new call is detected that no longer matches the current pattern, the system automatically "flushes" the buffer, writing the aggregated statistics to the file and beginning the detection of a new pattern.

This behavior is enabled by default and ensures your diagrams remain high-level and informative.

### Exception Stack Traces

Debugging exceptions in a sequence diagram can be hard if you only see the error message. MermaidTrace captures the **full Python stack trace** when a decorated function raises an exception.

-   In the Mermaid diagram, a note will appear next to the error arrow (`-x`).
-   Hovering or clicking (depending on your viewer) will show the full traceback, allowing you to debug without switching back to raw text logs.

### Simplified Object Representation

To keep diagrams readable, MermaidTrace automatically simplifies the representation of Python objects.

- **Default Objects**: Instead of showing memory addresses like `<__main__.AuthService object at 0x...>`, it shows just the class name: `<AuthService>`.
- **List/Tuple Grouping**: Consecutive identical items in lists or tuples are automatically grouped to save space. For example, `[<UserDB>, <UserDB>, <UserDB>]` is simplified to `[<UserDB> x 3]`.
- **Custom Reprs**: If you've defined a `__repr__` method, it will be used but safely truncated to prevent diagram bloat.
- **Truncation**: Large strings and deep data structures (dicts/lists) are automatically truncated based on global configuration.

## Advanced Configuration

### Async Mode (Performance)
For high-throughput production environments, enable `async_mode` to offload file writing to a background thread. This ensures your application's main thread is never blocked by disk I/O.

```python
configure_flow("flow.mmd", async_mode=True)
```

### Data Capture Control
You can control how function arguments and return values are recorded to keep diagrams clean and secure.

#### Global Configuration (`MermaidConfig`)
You can configure behavior globally via the `config` object or environment variables:

```python
from mermaid_trace import config

config.capture_args = False  # Disable argument capture globally
config.max_string_length = 100 # Set global truncation limit
```

Environment Variable Support:
- `MERMAID_TRACE_CAPTURE_ARGS`: `true`/`false`
- `MERMAID_TRACE_MAX_STRING_LENGTH`: number
- `MERMAID_TRACE_MAX_ARG_DEPTH`: number

#### Decorator Overrides
Parameters on the decorator take precedence over global configuration:

```python
# This specific function will still capture even if globally disabled
@trace(capture_args=True)
def specific_function():
    pass
```

### Explicit Naming
If the automatic class/function name inference isn't what you want, you can explicitly name the participant.

```python
@trace(name="AuthService")  # "AuthService" will appear in the diagram
def login():
    pass
```

### Flexible Handler Configuration

You can add MermaidTrace to an existing logging setup or append multiple handlers.

```python
# Append to existing handlers instead of clearing them
configure_flow("flow.mmd", append=True)

# Overwrite existing file on each start (default: True)
configure_flow("flow.mmd", overwrite=True)
```

## Production Best Practices

In production environments, systems often run for long periods, which can cause sequence diagram files to become extremely large and difficult to render. Here are several recommended solutions:

### Handling Long-Running Systems

If you must record all activities over a long period, it is recommended to use **Log Rotation**. MermaidTrace provides two specialized handlers to support automatic file splitting:

#### 1. Rotation by Size (`RotatingMermaidFileHandler`)

Automatically backs up the old file and starts a new one when the file reaches a specified size.

```python
import logging
from mermaid_trace import configure_flow
from mermaid_trace.handlers.mermaid_handler import RotatingMermaidFileHandler
from mermaid_trace.core.formatter import MermaidFormatter

# Create a handler that rotates by size
# maxBytes=1MB, backupCount=5 (keep 5 backups)
handler = RotatingMermaidFileHandler(
    "production_flow.mmd", 
    maxBytes=1024*1024, 
    backupCount=5
)
handler.setFormatter(MermaidFormatter())

# Configure flow with this handler
configure_flow(handlers=[handler], async_mode=True)
```

#### 2. Rotation by Time (`TimedRotatingMermaidFileHandler`)

Generates a new log file every day (or every hour).

```python
from mermaid_trace.handlers.mermaid_handler import TimedRotatingMermaidFileHandler

# Rotate once every midnight
handler = TimedRotatingMermaidFileHandler(
    "daily_flow.mmd",
    when="midnight",
    interval=1,
    backupCount=7
)
handler.setFormatter(MermaidFormatter())

configure_flow(handlers=[handler], async_mode=True)
```

### Request-Level Tracing (Recommended)

For high-traffic Web services, the most elegant solution is not to record everything, but to **isolate by request** or **record on demand**.

Although MermaidTrace currently defaults to writing everything to a single file, you can use it in conjunction with Trace IDs and external logging systems (like ELK, Splunk).
A more advanced approach is to enable detailed tracing only when an error is detected or specific trigger conditions are met.

### Sampling Tracing

To avoid performance overhead and storage pressure, you can implement sampling logic at the Web middleware layer:

```python
# Pseudo-code example
import random

@app.middleware("http")
async def trace_sampling_middleware(request: Request, call_next):
    # Trace only 1% of requests
    should_trace = random.random() < 0.01
    
    if should_trace:
        # Enable tracing context...
        pass
    
    response = await call_next(request)
    return response
```

## CLI Viewer

To view your diagrams, use the CLI:

```bash
mermaid-trace serve flow.mmd --port 8000
```

This starts a local server and opens your browser. It monitors the file for changes and auto-refreshes the page instantly.
